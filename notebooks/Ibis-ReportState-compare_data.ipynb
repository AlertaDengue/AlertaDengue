{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>Este módulo contém funções para interagir com o banco principal do projeto Alertadengue</i>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Callable\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from django.core.cache import cache\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ibis\n",
    "from ibis import config as cf\n",
    "from ibis.sql.postgres import existing_udf\n",
    "\n",
    "# local\n",
    "from dados.episem import episem, episem2date\n",
    "from ad_main import settings\n",
    "\n",
    "with cf.config_prefix('sql'):\n",
    "    k = 'default_limit'\n",
    "    cf.set_option(k, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSQL_URI = \"postgresql://{}:{}@{}:{}/{}\".format(\n",
    "    settings.PSQL_USER,\n",
    "    settings.PSQL_PASSWORD,\n",
    "    settings.PSQL_HOST,\n",
    "    settings.PSQL_PORT,\n",
    "    settings.PSQL_DB,\n",
    ")\n",
    "\n",
    "db_engine = create_engine(PSQL_URI)\n",
    "con = ibis.postgres.connect(url=PSQL_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>SELECT TABLE</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>municipio_geocodigo</th>\n",
       "      <th>id_regional</th>\n",
       "      <th>codigo_estacao_wu</th>\n",
       "      <th>nome_regional</th>\n",
       "      <th>limiar_preseason</th>\n",
       "      <th>limiar_posseason</th>\n",
       "      <th>limiar_epidemico</th>\n",
       "      <th>estacao_wu_sec</th>\n",
       "      <th>varcli</th>\n",
       "      <th>tcrit</th>\n",
       "      <th>ucrit</th>\n",
       "      <th>nome_macroreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>3300159</td>\n",
       "      <td>9</td>\n",
       "      <td>SBCP</td>\n",
       "      <td>Noroeste</td>\n",
       "      <td>44.802898</td>\n",
       "      <td>44.802898</td>\n",
       "      <td>89.605698</td>\n",
       "      <td>SBCP</td>\n",
       "      <td>temp_min</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>3300258</td>\n",
       "      <td>7</td>\n",
       "      <td>SBCB</td>\n",
       "      <td>Baixada Litorânea</td>\n",
       "      <td>17.195700</td>\n",
       "      <td>17.195700</td>\n",
       "      <td>34.391399</td>\n",
       "      <td>SBCB</td>\n",
       "      <td>temp_min</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>3300407</td>\n",
       "      <td>4</td>\n",
       "      <td>SBGW</td>\n",
       "      <td>Médio Paraíba</td>\n",
       "      <td>2.775830</td>\n",
       "      <td>2.775830</td>\n",
       "      <td>5.551670</td>\n",
       "      <td>SBRS</td>\n",
       "      <td>temp_min</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>3300506</td>\n",
       "      <td>6</td>\n",
       "      <td>SBGL</td>\n",
       "      <td>Serrana</td>\n",
       "      <td>18.922199</td>\n",
       "      <td>18.922199</td>\n",
       "      <td>37.844398</td>\n",
       "      <td>SBME</td>\n",
       "      <td>temp_min</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>3300704</td>\n",
       "      <td>7</td>\n",
       "      <td>SBCB</td>\n",
       "      <td>Baixada Litorânea</td>\n",
       "      <td>4.395920</td>\n",
       "      <td>2.510550</td>\n",
       "      <td>38.865398</td>\n",
       "      <td>SBBZ</td>\n",
       "      <td>temp_min</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  municipio_geocodigo  id_regional codigo_estacao_wu      nome_regional  \\\n",
       "0  79              3300159            9              SBCP           Noroeste   \n",
       "1  64              3300258            7              SBCB  Baixada Litorânea   \n",
       "2  27              3300407            4              SBGW      Médio Paraíba   \n",
       "3  51              3300506            6              SBGL            Serrana   \n",
       "4  65              3300704            7              SBCB  Baixada Litorânea   \n",
       "\n",
       "   limiar_preseason  limiar_posseason  limiar_epidemico estacao_wu_sec  \\\n",
       "0         44.802898         44.802898         89.605698           SBCP   \n",
       "1         17.195700         17.195700         34.391399           SBCB   \n",
       "2          2.775830          2.775830          5.551670           SBRS   \n",
       "3         18.922199         18.922199         37.844398           SBME   \n",
       "4          4.395920          2.510550         38.865398           SBBZ   \n",
       "\n",
       "     varcli  tcrit  ucrit nome_macroreg  \n",
       "0  temp_min   22.0    NaN          None  \n",
       "1  temp_min   22.0    NaN          None  \n",
       "2  temp_min   22.0    NaN          None  \n",
       "3  temp_min   22.0    NaN          None  \n",
       "4  temp_min   22.0    NaN          None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "schema_dengue_global = con.schema('Dengue_global')\n",
    "# schema_dengue_global.list_tables()\n",
    "t_estado = schema_dengue_global.table('regional_saude')\n",
    "# t_estado[t_estado.nome, t_estado.uf, t_estado.geocodigo].head().execute()\n",
    "t_estado.head().execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>SELECT CITIES BY UF</i>\n",
    "> geocode : name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3506003: 'Bauru'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preare cities dictionary\n",
    "\n",
    "# Atribute table name\n",
    "t_cities = schema_dengue_global.table('Municipio')\n",
    "\n",
    "# Create filters\n",
    "uf_filter_saopaulo = t_cities.uf == 'São Paulo' # Filter by uf name\n",
    "geo_filter_saopaulo = t_cities.geocodigo ==  3506003 # 3549805 # Filter by geocode\n",
    "keys = [t_cities.geocodigo, t_cities.nome] # List columns\n",
    "\n",
    "expr_cities = t_cities[uf_filter_saopaulo][keys]\n",
    "expr_cities = t_cities[geo_filter_saopaulo][keys]\n",
    "\n",
    "df_cities = expr_cities.execute().set_index('geocodigo')\n",
    "cities = df_cities.to_dict()['nome']\n",
    "\n",
    "# expr_cities\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rio de janeiro city geocode\n",
    "MRJ_GEOCODE = 3304557\n",
    "\n",
    "CID10 = {'dengue': 'A90', 'chikungunya': 'A920', 'zika': 'A928'}\n",
    "DISEASES_SHORT = ['dengue', 'chik', 'zika']\n",
    "\n",
    "STATE_NAME = {\n",
    "    'CE': 'Ceará',\n",
    "    'ES': 'Espírito Santo',\n",
    "    'MG': 'Minas Gerais',\n",
    "    'PR': 'Paraná',\n",
    "    'RJ': 'Rio de Janeiro',\n",
    "    'SP': 'São Paulo',\n",
    "}\n",
    "\n",
    "ALL_STATE_NAMES = STATE_NAME.copy()\n",
    "# TODO: add missing states here\n",
    "\n",
    "ALERT_COLOR = {1: 'verde', 2: 'amarelo', 3: 'laranja', 4: 'vermelho'}\n",
    "\n",
    "ALERT_CODE = dict(zip(ALERT_COLOR.values(), ALERT_COLOR.keys()))\n",
    "\n",
    "STATE_INITIAL = dict(zip(STATE_NAME.values(), STATE_NAME.keys()))\n",
    "ALL_STATE_INITIAL = dict(zip(ALL_STATE_NAMES.values(), ALL_STATE_NAMES.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ibis utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epi_week_expr() -> Callable:\n",
    "    \"\"\"\n",
    "    Return a UDF expression for epi_week function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Callable\n",
    "    \"\"\"\n",
    "    return existing_udf('epi_week', input_types=['date'], output_type='int64')\n",
    "\n",
    "\n",
    "def get_epiweek2date_expr() -> Callable:\n",
    "    \"\"\"\n",
    "    Return a UDF expression for epiweek2date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Callable\n",
    "    \"\"\"\n",
    "    return existing_udf(\n",
    "        'epiweek2date', input_types=['int64'], output_type='date'\n",
    "    )\n",
    "\n",
    "\n",
    "# general util functions\n",
    "\n",
    "\n",
    "def _nan_to_num_int_list(v):\n",
    "    \"\"\"\n",
    "\n",
    "    :param v: numpy.array\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.nan_to_num(v.fillna(0)).astype(int).tolist()\n",
    "    except Exception:\n",
    "        return np.nan_to_num(v).astype(int).tolist()\n",
    "\n",
    "\n",
    "def _episem(dt):\n",
    "    return episem(dt, sep='')\n",
    "\n",
    "\n",
    "def get_disease_suffix(disease: str):\n",
    "    \"\"\"\n",
    "\n",
    "    :param disease:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return (\n",
    "        ''\n",
    "        if disease == 'dengue'\n",
    "        else '_chik'\n",
    "        if disease == 'chikungunya'\n",
    "        else '_zika'\n",
    "        if disease == 'zika'\n",
    "        else ''\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPORT STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportState:\n",
    "    \"\"\"Report State class.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def _get_hist_disease_expr(\n",
    "        cls,\n",
    "        disease: str,\n",
    "        geocodes: List[int],\n",
    "        year_week_start: int,\n",
    "        year_week_end: int,\n",
    "    ) -> ibis.expr.types.Expr:\n",
    "        \"\"\"\n",
    "        Return an ibis expression with the history for a given disease.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        disease : str, {'dengue', 'chik', 'zika'}\n",
    "        geocodes : List[int]\n",
    "        year_week_start : int\n",
    "            The starting Year/Week, e.g.: 202002\n",
    "        year_week_end : int\n",
    "            The ending Year/Week, e.g.: 202005\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ibis.expr.types.Expr\n",
    "        \"\"\"\n",
    "        table_suffix = ''\n",
    "        if disease != 'dengue':\n",
    "            table_suffix = '_{}'.format(disease)\n",
    "\n",
    "        schema_city = con.schema('Municipio')\n",
    "        t_hist = schema_city.table('Historico_alerta{}'.format(table_suffix))\n",
    "\n",
    "        case_level = (\n",
    "            ibis.case()\n",
    "            .when((t_hist.nivel.cast('string') == '1'), 'verde')\n",
    "            .when((t_hist.nivel.cast('string') == '2'), 'amarelo')\n",
    "            .when((t_hist.nivel.cast('string') == '3'), 'laranja')\n",
    "            .when((t_hist.nivel.cast('string') == '4'), 'vermelho')\n",
    "            .else_('-')\n",
    "            .end()\n",
    "        ).name(f'nivel_{disease}')\n",
    "\n",
    "        hist_keys = [\n",
    "            t_hist.SE.name(f'SE_{disease}'),\n",
    "            t_hist.casos.name(f'casos_{disease}'),\n",
    "            t_hist.p_rt1.name(f'p_rt1_{disease}'),\n",
    "            t_hist.casos_est.name(f'casos_est_{disease}'),\n",
    "            t_hist.p_inc100k.name(f'p_inc100k_{disease}'),\n",
    "            t_hist.nivel.name(f'level_code_{disease}'),\n",
    "            case_level,\n",
    "            t_hist.municipio_geocodigo.name(f'geocode_{disease}'),\n",
    "        ]\n",
    "\n",
    "        hist_filter = (\n",
    "            t_hist['SE'].between(year_week_start, year_week_end)\n",
    "        ) & (t_hist['municipio_geocodigo'].isin(geocodes))\n",
    "\n",
    "        return t_hist[hist_filter][hist_keys].sort_by(f'SE_{disease}')\n",
    "\n",
    "    @classmethod\n",
    "    def _get_twitter_expr(\n",
    "        cls, geocodes_list: List[int], year_week_start: int, year_week_end: int\n",
    "    ) -> ibis.expr.types.Expr:\n",
    "        \"\"\"\n",
    "        Return a twitter expression for given parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        geocodes_list : List[int]\n",
    "        year_week_start : int\n",
    "        year_week_end : int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ibis.expr.types.Expr\n",
    "        \"\"\"\n",
    "        schema_city = con.schema('Municipio')\n",
    "        epi_week_fn = get_epi_week_expr()\n",
    "\n",
    "        t_tweet = schema_city.table('Tweet')\n",
    "        filter_tweet_cities = t_tweet.Municipio_geocodigo.isin(geocodes_list)\n",
    "        t_tweet = t_tweet[filter_tweet_cities]\n",
    "        t_tweet = t_tweet.mutate(SE_twitter=epi_week_fn(t_tweet.data_dia))\n",
    "\n",
    "        expr_tweet = t_tweet.groupby(\n",
    "            [t_tweet.SE_twitter, t_tweet.Municipio_geocodigo]\n",
    "        ).aggregate(n_tweets=t_tweet.numero.sum())\n",
    "\n",
    "        filter_tweet = t_tweet.SE_twitter.between(\n",
    "            year_week_start, year_week_end\n",
    "        )\n",
    "\n",
    "        return expr_tweet[filter_tweet].sort_by(('SE_twitter', False))\n",
    "\n",
    "    @classmethod\n",
    "    def _get_climate_wu_expr(\n",
    "        cls, var_climate: str, station_id: str\n",
    "    ) -> ibis.expr.types.Expr:\n",
    "        \"\"\"\n",
    "        Return an ibis expression for climate_wu for given parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_climate : str, {'umid_max', 'temp_min'}\n",
    "        station_id : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ibis.expr.types.Expr\n",
    "        \"\"\"\n",
    "        epi_week_fn = get_epi_week_expr()\n",
    "\n",
    "        schema_city = con.schema('Municipio')\n",
    "\n",
    "        t_climate_wu = schema_city.table('Clima_wu')\n",
    "\n",
    "        expr_filter = t_climate_wu.Estacao_wu_estacao_id == station_id\n",
    "        t_climate_wu = t_climate_wu[expr_filter]\n",
    "        t_climate_wu = t_climate_wu.mutate(\n",
    "            epiweek_climate=epi_week_fn(t_climate_wu.data_dia)\n",
    "        )\n",
    "\n",
    "        expr_climate_wu = t_climate_wu.groupby(\n",
    "            [t_climate_wu.epiweek_climate]\n",
    "        ).aggregate(\n",
    "            **{var_climate: t_climate_wu[var_climate].mean().name(var_climate)}\n",
    "        )\n",
    "\n",
    "        return expr_climate_wu.sort_by(t_climate_wu.epiweek_climate)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_report_data(\n",
    "        cls,\n",
    "        geocodes_list: List[int],\n",
    "        year_week_start: int,\n",
    "        year_week_end: int,\n",
    "        var_climate: str,\n",
    "        station_id: str,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Get Repor State Data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        geocodes_list : List[int]\n",
    "        year_week_start : int\n",
    "            The starting Year/Week e.g.: 202002\n",
    "        year_week_end : int\n",
    "            The ending Year/Week e.g.: 202005\n",
    "        var_climate : str, {'umid_max', 'temp_min'}\n",
    "        station_id : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        hist_disease_expr = {}\n",
    "        hist_prev = None\n",
    "        joined_expr = None\n",
    "        previous_disease = None\n",
    "#         import pdb; pdb.set_trace()\n",
    "\n",
    "        for disease in DISEASES_SHORT:\n",
    "            hist_expr = cls._get_hist_disease_expr(\n",
    "                disease, geocodes_list, year_week_start, year_week_end,\n",
    "            )\n",
    "            hist_disease_expr[disease] = hist_expr\n",
    "\n",
    "            if joined_expr is None:\n",
    "                joined_expr = hist_expr\n",
    "            else:\n",
    "                # todo: review join approach\n",
    "                hist_prev = hist_disease_expr[previous_disease]\n",
    "                joined_cond = (\n",
    "                    hist_prev[f'SE_{previous_disease}']\n",
    "                    == hist_expr[f'SE_{disease}']\n",
    "                ) & (\n",
    "                    hist_prev[f'geocode_{previous_disease}']\n",
    "                    == hist_expr[f'geocode_{disease}']\n",
    "                )\n",
    "                joined_expr = joined_expr.left_join(hist_expr, joined_cond)\n",
    "            previous_disease = disease\n",
    "\n",
    "        # twitter data\n",
    "        expr_tweet = cls._get_twitter_expr(\n",
    "            geocodes_list, year_week_start, year_week_end,\n",
    "        )\n",
    "        expr_dengue = hist_disease_expr['dengue']\n",
    "\n",
    "        joined_expr = joined_expr.left_join(\n",
    "            expr_tweet,\n",
    "            (\n",
    "                (expr_tweet.Municipio_geocodigo == expr_dengue.geocode_dengue)\n",
    "                & (expr_tweet.SE_twitter == expr_dengue.SE_dengue)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        climate_wu_expr = cls._get_climate_wu_expr(var_climate, station_id)\n",
    "\n",
    "        joined_expr = joined_expr.left_join(\n",
    "            climate_wu_expr,\n",
    "            hist_disease_expr['dengue'].SE_dengue\n",
    "            == climate_wu_expr.epiweek_climate,\n",
    "        ).materialize()\n",
    "\n",
    "        epiweek2date_fn = get_epiweek2date_expr()\n",
    "\n",
    "        k = ['casos', 'p_inc100k', 'casos_est', 'p_rt1', 'nivel', 'level_code']\n",
    "        proj = [\n",
    "            joined_expr['{}_{}'.format(v, d)]\n",
    "            for v in k\n",
    "            for d in DISEASES_SHORT\n",
    "        ]\n",
    "        proj.extend(\n",
    "            [\n",
    "                joined_expr[var_climate],\n",
    "                joined_expr['n_tweets'],\n",
    "                joined_expr['geocode_dengue'].name('geocode'),\n",
    "                joined_expr['SE_dengue'].name('SE'),\n",
    "                epiweek2date_fn(joined_expr.SE_dengue).name('init_date_week'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return joined_expr[proj].sort_by(['SE', 'geocode']).execute()\n",
    "\n",
    "    @classmethod\n",
    "    def _format_data(cls, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Format the data for plotting.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        # make a copy\n",
    "        df = df.copy()\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        if not df.empty:\n",
    "            dfs = []\n",
    "\n",
    "            # merge with a range date dataframe to keep empty week on the data\n",
    "            ts_date = pd.date_range(\n",
    "                df['init_date_week'].min(),\n",
    "                df['init_date_week'].max(),\n",
    "                freq='7D',\n",
    "            )\n",
    "            df_date = pd.DataFrame({'init_date_week': ts_date})\n",
    "\n",
    "            for geocode in df.geocode.unique():\n",
    "                df_ = df[df.geocode == geocode].sort_values('init_date_week')\n",
    "\n",
    "                df_date_ = df_date.set_index(\n",
    "                    df_.init_date_week.map(\n",
    "                        lambda x: int(episem(str(x)[:10], sep=''))\n",
    "                    ),\n",
    "                    drop=True,\n",
    "                )\n",
    "\n",
    "                df_.index.name = None\n",
    "                df_date_.index.name = None\n",
    "\n",
    "                df_['init_date_week'] = pd.to_datetime(\n",
    "                    df_['init_date_week'], errors='coerce'\n",
    "                )\n",
    "\n",
    "                dfs.append(\n",
    "                    pd.merge(df_, df_date_, how='outer', on='init_date_week',)\n",
    "                )\n",
    "\n",
    "            df = pd.concat(dfs)\n",
    "\n",
    "        df.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "        for d in DISEASES_SHORT:\n",
    "            k = 'p_rt1_{}'.format(d)\n",
    "            df[k] = (df[k] * 100).fillna(0)\n",
    "            k = 'casos_est_{}'.format(d)\n",
    "            df[k] = df[k].fillna(0).round(0)\n",
    "            k = 'p_inc100k_{}'.format(d)\n",
    "            df[k] = df[k].fillna(0).round(0)\n",
    "\n",
    "            df.rename(\n",
    "                columns={\n",
    "                    'p_inc100k_{}'.format(d): 'incidência {}'.format(d),\n",
    "                    'casos_{}'.format(d): 'casos notif. {}'.format(d),\n",
    "                    'casos_est_{}'.format(d): 'casos est. {}'.format(d),\n",
    "                    'p_rt1_{}'.format(d): 'pr(incid. subir) {}'.format(d),\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "\n",
    "        df.n_tweets = df.n_tweets.fillna(0).round(0)\n",
    "\n",
    "        return df.rename(\n",
    "            columns={\n",
    "                'umid_max': 'umid.max',\n",
    "                'temp_min': 'temp.min',\n",
    "                'n_tweets': 'tweets',\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def read_disease_data(\n",
    "        cls,\n",
    "        cities: Dict[int, str],\n",
    "        station_id: str,\n",
    "        year_week: int,\n",
    "        var_climate: str,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return a disease dataframe from given parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cities : dict[int, str]\n",
    "        station_id : str\n",
    "        year_week : int\n",
    "            The last Year/Week for searching reference.\n",
    "        var_climate : str, {'umid_max', 'temp_min'}\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "\n",
    "        \"\"\"\n",
    "        year_week_start = year_week - 200\n",
    "        year_week_end = year_week\n",
    "        geocodes_list = [v for v in cities]\n",
    "\n",
    "        df = cls._get_report_data(\n",
    "            geocodes_list=geocodes_list,\n",
    "            year_week_start=year_week_start,\n",
    "            year_week_end=year_week_end,\n",
    "            var_climate=var_climate,\n",
    "            station_id=station_id,\n",
    "        )\n",
    "        return cls._format_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REPORT DATA PARAMETERS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_climate = 'umid_max'\n",
    "# year_week = 202002\n",
    "# station_id = 'SBSR'\n",
    "\n",
    "geocodes_list=[3506003]\n",
    "year_week_start= 202003\n",
    "year_week_end= 202003\n",
    "var_climate = 'umid_max'\n",
    "year_week = 202002\n",
    "station_id = 'SBSR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibis = ReportState.read_disease_data(cities, station_id, year_week, var_climate)\n",
    "df_ibis.set_index(\"SE\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class OldReportState:\n",
    "    diseases = ['dengue', 'chik', 'zika']\n",
    "\n",
    "    @classmethod\n",
    "    def _read_disease_data(\n",
    "        cls, cities: dict, station_id: str, year_week: int, var_climate: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        :param cities:\n",
    "        :param station_id:\n",
    "        :param year_week:\n",
    "        :param var_climate:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        k = ['casos', 'p_inc100k', 'casos_est', 'p_rt1', 'nivel', 'level_code']\n",
    "\n",
    "        k = ['{}_{}'.format(v, d) for v in k for d in cls.diseases]\n",
    "\n",
    "        k.append(var_climate)\n",
    "        k.append('n_tweets')\n",
    "        k.append('geocode_dengue AS geocode')\n",
    "        k.append('\"SE_dengue\" AS \"SE\"')\n",
    "        k.append('epiweek2date(\"SE_dengue\") AS init_date_week')\n",
    "\n",
    "        general_param = {\n",
    "            'year_week_start': year_week - 200,\n",
    "            'year_week_end': year_week,\n",
    "            'geocodes': ','.join(map(lambda v: \"'{}'\".format(v), cities)),\n",
    "            'var_climate': var_climate,\n",
    "            'station_id': station_id,\n",
    "        }\n",
    "\n",
    "        sql = ''\n",
    "        previous_disease = ''\n",
    "        for disease in cls.diseases:\n",
    "            _param = dict(general_param)\n",
    "            _param['disease'] = disease\n",
    "\n",
    "            table_suffix = ''\n",
    "            if disease != 'dengue':\n",
    "                table_suffix = '_{}'.format(disease)\n",
    "\n",
    "            _param['table_suffix'] = table_suffix\n",
    "\n",
    "            sql_ = (\n",
    "                '''\n",
    "            (SELECT\n",
    "               hist.\"SE\" AS \"SE_%(disease)s\",\n",
    "               hist.casos AS casos_%(disease)s,\n",
    "               hist.p_rt1 AS p_rt1_%(disease)s,\n",
    "               hist.casos_est AS casos_est_%(disease)s,\n",
    "               hist.p_inc100k AS p_inc100k_%(disease)s,\n",
    "               hist.nivel AS level_code_%(disease)s,\n",
    "               (CASE\n",
    "                  WHEN hist.nivel=1 THEN 'verde'\n",
    "                  WHEN hist.nivel=2 THEN 'amarelo'\n",
    "                  WHEN hist.nivel=3 THEN 'laranja'\n",
    "                  WHEN hist.nivel=4 THEN 'vermelho'\n",
    "                  ELSE '-'\n",
    "                END) AS nivel_%(disease)s,\n",
    "                hist.municipio_geocodigo AS geocode_%(disease)s\n",
    "            FROM\n",
    "             \"Municipio\".\"Historico_alerta%(table_suffix)s\" AS hist\n",
    "            WHERE\n",
    "             hist.\"SE\" BETWEEN %(year_week_start)s AND %(year_week_end)s\n",
    "             AND hist.municipio_geocodigo IN (%(geocodes)s)\n",
    "            ORDER BY \"SE_%(disease)s\" DESC\n",
    "            ) AS %(disease)s\n",
    "            '''\n",
    "                % _param\n",
    "            )\n",
    "\n",
    "            if not sql:\n",
    "                sql = sql_\n",
    "            else:\n",
    "                sql += '''\n",
    "                    LEFT JOIN {0}\n",
    "                    ON (\n",
    "                      {1}.\"SE_{1}\" = {2}.\"SE_{2}\"\n",
    "                      AND {1}.geocode_{1} = {2}.geocode_{2}\n",
    "                    )\n",
    "                '''.format(\n",
    "                    sql_, previous_disease, disease\n",
    "                )\n",
    "            previous_disease = disease\n",
    "\n",
    "        tweet_join = (\n",
    "            '''\n",
    "        LEFT JOIN (\n",
    "           SELECT\n",
    "             epi_week(data_dia) AS \"SE_twitter\",\n",
    "             SUM(numero) as n_tweets,\n",
    "             \"Municipio_geocodigo\"\n",
    "           FROM \"Municipio\".\"Tweet\"\n",
    "           WHERE\n",
    "             \"Municipio_geocodigo\" IN (%(geocodes)s)\n",
    "             AND epi_week(data_dia)\n",
    "               BETWEEN %(year_week_start)s AND %(year_week_end)s\n",
    "           GROUP BY \"SE_twitter\", \"Municipio_geocodigo\"\n",
    "           ORDER BY \"SE_twitter\" DESC\n",
    "        ) AS tweets\n",
    "           ON (\n",
    "             \"Municipio_geocodigo\"=dengue.\"geocode_dengue\"\n",
    "             AND tweets.\"SE_twitter\"=dengue.\"SE_dengue\"\n",
    "           )\n",
    "        '''\n",
    "            % general_param\n",
    "        )\n",
    "\n",
    "        climate_join = (\n",
    "            '''\n",
    "        LEFT JOIN (\n",
    "          SELECT\n",
    "             epi_week(data_dia) AS epiweek_climate,\n",
    "             AVG(%(var_climate)s) AS %(var_climate)s\n",
    "          FROM \"Municipio\".\"Clima_wu\"\n",
    "          WHERE \"Estacao_wu_estacao_id\" = '%(station_id)s'\n",
    "          GROUP BY epiweek_climate\n",
    "          ORDER BY epiweek_climate\n",
    "        ) AS climate_wu\n",
    "           ON (dengue.\"SE_dengue\"=climate_wu.epiweek_climate)\n",
    "        '''\n",
    "            % general_param\n",
    "        )\n",
    "\n",
    "        sql += climate_join + tweet_join\n",
    "\n",
    "        sql = ' SELECT {} FROM ({}) AS data'.format(','.join(k), sql)\n",
    "\n",
    "        df = pd.read_sql(sql, index_col='SE', con=db_engine)\n",
    "\n",
    "        if not df.empty:\n",
    "            dfs = []\n",
    "\n",
    "            # merge with a range date dataframe to keep empty week on the data\n",
    "            ts_date = pd.date_range(\n",
    "                df['init_date_week'].min(),\n",
    "                df['init_date_week'].max(),\n",
    "                freq='7D',\n",
    "            )\n",
    "            df_date = pd.DataFrame({'init_date_week': ts_date})\n",
    "\n",
    "            for geocode in df.geocode.unique():\n",
    "                df_ = df[df.geocode == geocode].sort_values('init_date_week')\n",
    "\n",
    "                df_date_ = df_date.set_index(\n",
    "                    df_.init_date_week.map(\n",
    "                        lambda x: int(episem(str(x)[:10], sep=''))\n",
    "                    ),\n",
    "                    drop=True,\n",
    "                )\n",
    "\n",
    "                df_.index.name = \"SE\"\n",
    "                df_date_.index.name = None\n",
    "\n",
    "                df_['init_date_week'] = pd.to_datetime(\n",
    "                    df_['init_date_week'], errors='coerce'\n",
    "                )\n",
    "\n",
    "                dfs.append(\n",
    "                    pd.merge(\n",
    "                        df_,\n",
    "                        df_date_,\n",
    "                        how='outer',\n",
    "                        on='init_date_week',\n",
    "                        left_index=True,\n",
    "                        right_index=True,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            df = pd.concat(dfs)\n",
    "\n",
    "        df.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "        for d in cls.diseases:\n",
    "            k = 'p_rt1_{}'.format(d)\n",
    "            df[k] = (df[k] * 100).fillna(0)\n",
    "            k = 'casos_est_{}'.format(d)\n",
    "            df[k] = df[k].fillna(0).round(0)\n",
    "            k = 'p_inc100k_{}'.format(d)\n",
    "            df[k] = df[k].fillna(0).round(0)\n",
    "\n",
    "            df.rename(\n",
    "                columns={\n",
    "                    'p_inc100k_{}'.format(d): 'incidência {}'.format(d),\n",
    "                    'casos_{}'.format(d): 'casos notif. {}'.format(d),\n",
    "                    'casos_est_{}'.format(d): 'casos est. {}'.format(d),\n",
    "                    'p_rt1_{}'.format(d): 'pr(incid. subir) {}'.format(d),\n",
    "                },\n",
    "                inplace=True,\n",
    "                \n",
    "            )\n",
    "            \n",
    "\n",
    "        df.n_tweets = df.n_tweets.fillna(0).round(0)\n",
    "\n",
    "        return df.rename(\n",
    "            columns={\n",
    "                'umid_max': 'umid.max',\n",
    "                'temp_min': 'temp.min',\n",
    "                'n_tweets': 'tweets',\n",
    "            }\n",
    "        )\n",
    "\n",
    "from dados.episem import episem, episem2date\n",
    "\n",
    "df_sql = OldReportState._read_disease_data(cities, station_id, year_week, var_climate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data in slice columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 105 entries, 201802 to 202002\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   incidência dengue        105 non-null    float64\n",
      " 1   incidência chik          105 non-null    float64\n",
      " 2   incidência zika          105 non-null    float64\n",
      " 3   casos est. dengue        105 non-null    float64\n",
      " 4   casos est. chik          105 non-null    float64\n",
      " 5   casos est. zika          105 non-null    float64\n",
      " 6   pr(incid. subir) dengue  105 non-null    float64\n",
      " 7   pr(incid. subir) chik    105 non-null    float64\n",
      " 8   pr(incid. subir) zika    105 non-null    float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 8.2 KB\n"
     ]
    }
   ],
   "source": [
    "a = df_sql.iloc[:, 3:12].astype(float)\n",
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 105 entries, 201802 to 202002\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   incidência dengue        105 non-null    float64\n",
      " 1   incidência chik          105 non-null    float64\n",
      " 2   incidência zika          105 non-null    float64\n",
      " 3   casos est. dengue        105 non-null    float64\n",
      " 4   casos est. chik          105 non-null    float64\n",
      " 5   casos est. zika          105 non-null    float64\n",
      " 6   pr(incid. subir) dengue  105 non-null    float64\n",
      " 7   pr(incid. subir) chik    105 non-null    float64\n",
      " 8   pr(incid. subir) zika    105 non-null    float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 8.2 KB\n"
     ]
    }
   ],
   "source": [
    "b = df_ibis.iloc[:, 3:12].astype(float)\n",
    "b.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b>COMPARE DATAFRAMES</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
