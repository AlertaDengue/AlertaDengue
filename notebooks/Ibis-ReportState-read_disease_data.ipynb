{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from typing import List\n",
    "import ibis\n",
    "from ibis import config as cf\n",
    "from ibis.sql.postgres import existing_udf\n",
    "import datetime\n",
    "\n",
    "from ad_main import settings\n",
    "import pandas as pd\n",
    "\n",
    "with cf.config_prefix('sql'):\n",
    "    cf.set_option('default_limit', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auth_group',\n",
       " 'auth_group_permissions',\n",
       " 'auth_permission',\n",
       " 'auth_user',\n",
       " 'auth_user_groups',\n",
       " 'auth_user_user_permissions',\n",
       " 'chunked_upload_chunkedupload',\n",
       " 'dbf_dbf',\n",
       " 'dbf_dbfchunkedupload',\n",
       " 'django_admin_log',\n",
       " 'django_content_type',\n",
       " 'django_migrations',\n",
       " 'django_session',\n",
       " 'geography_columns',\n",
       " 'geometry_columns',\n",
       " 'raster_columns',\n",
       " 'raster_overviews',\n",
       " 'spatial_ref_sys',\n",
       " 'teste',\n",
       " 'uf_total_chik_view',\n",
       " 'uf_total_view',\n",
       " 'uf_total_zika_view']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PSQL_URI = \"postgresql://{}:{}@{}:{}/{}\".format(\n",
    "    settings.PSQL_USER,\n",
    "    settings.PSQL_PASSWORD,\n",
    "    settings.PSQL_HOST,\n",
    "    settings.PSQL_PORT,\n",
    "    settings.PSQL_DB,\n",
    ")\n",
    "\n",
    "db_engine = create_engine(PSQL_URI)\n",
    "con = ibis.postgres.connect(url=PSQL_URI)\n",
    "con.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISEASES_SHORT = ['dengue', 'chik', 'zika']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CID10', 'Municipio', 'estado', 'parameters', 'regional_saude']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_dengue_global = con.schema('Dengue_global')\n",
    "schema_dengue_global.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bairro',\n",
       " 'Clima_Satelite',\n",
       " 'Clima_cemaden',\n",
       " 'Clima_wu',\n",
       " 'Estacao_cemaden',\n",
       " 'Estacao_wu',\n",
       " 'Historico_alerta',\n",
       " 'Historico_alerta_chik',\n",
       " 'Historico_alerta_zika',\n",
       " 'Localidade',\n",
       " 'Notificacao',\n",
       " 'Ovitrampa',\n",
       " 'Tweet',\n",
       " 'alerta_mrj',\n",
       " 'alerta_mrj_chik',\n",
       " 'alerta_mrj_zika',\n",
       " 'historico_casos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_city = con.schema('Municipio')\n",
    "schema_city.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>uf</th>\n",
       "      <th>geocodigo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>mg</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERNAMBUCO</td>\n",
       "      <td>pe</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALAGOAS</td>\n",
       "      <td>al</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARANHÃO</td>\n",
       "      <td>ma</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RONDÔNIA</td>\n",
       "      <td>ro</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nome  uf  geocodigo\n",
       "0  MINAS GERAIS  mg         31\n",
       "1    PERNAMBUCO  pe         26\n",
       "2       ALAGOAS  al         27\n",
       "3      MARANHÃO  ma         21\n",
       "4      RONDÔNIA  ro         11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_estado = schema_dengue_global.table('estado')\n",
    "t_estado[t_estado.nome, t_estado.uf, t_estado.geocodigo].head().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ref_0\n",
       "PostgreSQLTable[table]\n",
       "  name: Municipio\n",
       "  schema:\n",
       "    geocodigo : int32\n",
       "    nome : string\n",
       "    geojson : string\n",
       "    populacao : int64\n",
       "    uf : string\n",
       "\n",
       "Selection[table]\n",
       "  table:\n",
       "    Table: ref_0\n",
       "  selections:\n",
       "    geocodigo = Column[int32*] 'geocodigo' from table\n",
       "      ref_0\n",
       "    nome = Column[string*] 'nome' from table\n",
       "      ref_0\n",
       "  predicates:\n",
       "    Equals[boolean*]\n",
       "      left:\n",
       "        uf = Column[string*] 'uf' from table\n",
       "          ref_0\n",
       "      right:\n",
       "        Literal[string]\n",
       "          Ceará"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preare cities dictionary\n",
    "t_cities = schema_dengue_global.table('Municipio')\n",
    "\n",
    "uf_filter_ceara = t_cities.uf == 'Ceará'\n",
    "keys = [t_cities.geocodigo, t_cities.nome]\n",
    "\n",
    "expr_cities = t_cities[uf_filter_ceara][keys]\n",
    "\n",
    "df_cities = expr_cities.execute().set_index('geocodigo')\n",
    "cities = df_cities.to_dict()['nome']\n",
    "\n",
    "expr_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{2305233: 'Horizonte', 2305266: 'Ibaretama', 23053...\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(cities)[:50] + '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostgreSQLTable[table]\n",
       "  name: regional_saude\n",
       "  schema:\n",
       "    id : int32\n",
       "    municipio_geocodigo : int32\n",
       "    id_regional : int32\n",
       "    codigo_estacao_wu : string\n",
       "    nome_regional : string\n",
       "    limiar_preseason : float32\n",
       "    limiar_posseason : float32\n",
       "    limiar_epidemico : float32\n",
       "    estacao_wu_sec : string\n",
       "    varcli : string\n",
       "    tcrit : float64\n",
       "    ucrit : float64\n",
       "    nome_macroreg : string"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare station_id\n",
    "t_rsaude = schema_dengue_global.table('regional_saude')\n",
    "t_rsaude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   municipio_geocodigo codigo_estacao_wu    varcli     uf         nome\n",
      "0              2305233              SBFZ  umid_max  Ceará    Horizonte\n",
      "1              2305266              SBTE  umid_max  Ceará    Ibaretama\n",
      "2              2305308              SBFZ  umid_max  Ceará     Ibiapina\n",
      "3              2305332              SBTE  umid_max  Ceará  Ibicuitinga\n",
      "4              2305357              SBFZ  umid_max  Ceará       Icapuí\n"
     ]
    }
   ],
   "source": [
    "rsaude_keys = [\n",
    "    t_rsaude.municipio_geocodigo,\n",
    "    t_rsaude.codigo_estacao_wu,\n",
    "    t_rsaude.varcli,\n",
    "    t_cities.uf,\n",
    "    t_cities.nome\n",
    "]\n",
    "\n",
    "expr_rsaude = t_rsaude.join(\n",
    "    t_cities, \n",
    "    (t_rsaude.municipio_geocodigo == t_cities.geocodigo) \n",
    "    & (t_cities.uf == 'Ceará')\n",
    ")\n",
    "print(expr_rsaude[rsaude_keys].head().execute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_climate = 'umid_max'\n",
    "year_week = 202002\n",
    "station_id = 'SBFZ'\n",
    "\n",
    "general_param = {\n",
    "    'year_week_start': year_week - 200,\n",
    "    'year_week_end': year_week,\n",
    "    'geocodes': ','.join(map(lambda v: repr(str(v)), cities)),\n",
    "    'geocodes_list': [v for v in cities],\n",
    "    'var_climate': var_climate,\n",
    "    'station_id': station_id,\n",
    "}\n",
    "\n",
    "disease = 'dengue'\n",
    "\n",
    "_param = dict(general_param)\n",
    "_param['disease'] = disease\n",
    "\n",
    "table_suffix = ''\n",
    "if disease != 'dengue':\n",
    "    table_suffix = '_{}'.format(disease)\n",
    "\n",
    "_param['table_suffix'] = table_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ref_0\n",
       "PostgreSQLTable[table]\n",
       "  name: Tweet\n",
       "  schema:\n",
       "    id : int64\n",
       "    Municipio_geocodigo : int32\n",
       "    data_dia : date\n",
       "    numero : int32\n",
       "    CID10_codigo : string\n",
       "\n",
       "ref_1\n",
       "Selection[table]\n",
       "  table:\n",
       "    Table: ref_0\n",
       "  predicates:\n",
       "    Contains[boolean*]\n",
       "      value:\n",
       "        Municipio_geocodigo = Column[int32*] 'Municipio_geocodigo' from table\n",
       "          ref_0\n",
       "      options:\n",
       "        Literal[set<int32>]\n",
       "          frozenset({2308609, 2304004, 2308104, 2303501, 2312205, 2307601, 2311702, 2313757, 2303006, 2307106, 2313252, 2302503, 2311207, 2306603, 2310704, 2307635, 2302008, 2306108, 2311231, 2301505, 2307650, 2310209, 2305605, 2301000, 2309706, 2305100, 2313807, 2309201, 2313302, 2300507, 2304608, 2311264, 2308708, 2304103, 2302057, 2312809, 2308203, 2303600, 2312304, 2310258, 2307700, 2305654, 2311801, 2303105, 2307205, 2313351, 2302602, 2311306, 2306702, 2304657, 2310803, 2302107, 2306207, 2301604, 2310308, 2305704, 2303659, 2309805, 2313906, 2309300, 2301109, 2307254, 2305209, 2313401, 2311355, 2300606, 2304707, 2310852, 2300101, 2308807, 2304202, 2312908, 2308302, 2306256, 2305233, 2312403, 2311900, 2303709, 2307809, 2313955, 2303204, 2307304, 2304236, 2302701, 2311405, 2306801, 2305266, 2300150, 2310902, 2304251, 2302206, 2308351, 2306306, 2301703, 2310407, 2305803, 2304269, 2309904, 2314003, 2304277, 2311959, 2301208, 2308377, 2305308, 2304285, 2313500, 2300705, 2309409, 2304806, 2310951, 2300200, 2308906, 2304301, 2313005, 2308401, 2305332, 2312502, 2303808, 2307908, 2303303, 2312007, 2301257, 2307403, 2305357, 2302800, 2311504, 2300754, 2309458, 2306900, 2313559, 2304350, 2302305, 2311009, 2306405, 2301802, 2310506, 2305902, 2310001, 2314102, 2301307, 2305407, 2300804, 2309508, 2304905, 2313609, 2309003, 2304400, 2313104, 2308500, 2300309, 2312601, 2301851, 2303907, 2308005, 2303402, 2312106, 2307502, 2311603, 2304954, 2303931, 2302909, 2307007, 2302404, 2311108, 2306504, 2304459, 2301901, 2310605, 2303956, 2310100, 2306009, 2301406, 2305506, 2300903, 2309607, 2305001, 2313708, 2309102, 2313203, 2300408, 2306553, 2312700, 2304509, 2301950})\n",
       "\n",
       "ref_2\n",
       "Selection[table]\n",
       "  table:\n",
       "    Table: ref_1\n",
       "  selections:\n",
       "    Table: ref_1\n",
       "    SE_twitter = epi_week_0[int32*]\n",
       "      v0:\n",
       "        data_dia = Column[date*] 'data_dia' from table\n",
       "          ref_1\n",
       "\n",
       "Aggregation[table]\n",
       "  table:\n",
       "    Table: ref_2\n",
       "  metrics:\n",
       "    n_tweets = Sum[int64]\n",
       "      numero = Column[int32*] 'numero' from table\n",
       "        ref_2\n",
       "      where:\n",
       "        None\n",
       "  by:\n",
       "    SE_twitter = Column[int32*] 'SE_twitter' from table\n",
       "      ref_2\n",
       "    Municipio_geocodigo = Column[int32*] 'Municipio_geocodigo' from table\n",
       "      ref_2\n",
       "  predicates:\n",
       "    Between[boolean*]\n",
       "      SE_twitter = Column[int32*] 'SE_twitter' from table\n",
       "        ref_2\n",
       "      lower_bound:\n",
       "        Literal[int32]\n",
       "          201802\n",
       "      upper_bound:\n",
       "        Literal[int32]\n",
       "          202002\n",
       "  sort_keys:\n",
       "    SortKey[array-sort]\n",
       "      expr:\n",
       "        SE_twitter = Column[int32*] 'SE_twitter' from table\n",
       "          ref_2\n",
       "      ascending:\n",
       "        False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epi_week_fn = existing_udf(\n",
    "    'epi_week',\n",
    "    input_types=['date'],\n",
    "    output_type='int32'\n",
    ")\n",
    "\n",
    "t_tweet = schema_city.table('Tweet')\n",
    "filter_tweet_cities = t_tweet.Municipio_geocodigo.isin(\n",
    "    general_param['geocodes_list']\n",
    ")\n",
    "t_tweet = t_tweet[filter_tweet_cities]\n",
    "t_tweet = t_tweet.mutate(SE_twitter=epi_week_fn(t_tweet.data_dia))\n",
    "\n",
    "expr_tweet = t_tweet.groupby([\n",
    "    t_tweet.SE_twitter,\n",
    "    t_tweet.Municipio_geocodigo,\n",
    "    \n",
    "]).aggregate(\n",
    "    n_tweets=t_tweet.numero.sum()\n",
    ")\n",
    "\n",
    "filter_tweet = (\n",
    "    t_tweet.SE_twitter.between(\n",
    "        general_param['year_week_start'], \n",
    "        general_param['year_week_end']\n",
    "    )\n",
    ")\n",
    "\n",
    "# ORDER BY \"SE_twitter\" DESC\n",
    "expr_tweet = expr_tweet[filter_tweet].sort_by(('SE_twitter', False))\n",
    "expr_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epi_week_expr():\n",
    "    return existing_udf(\n",
    "        'epi_week',\n",
    "        input_types=['date'],\n",
    "        output_type='int64'\n",
    "    )\n",
    "\n",
    "def get_epiweek2date_expr():\n",
    "    return existing_udf(\n",
    "        'epiweek2date',\n",
    "        input_types=['int64'],\n",
    "        output_type='date'\n",
    "    )\n",
    "\n",
    "\n",
    "def get_hist_disease_expr(\n",
    "    disease: str,\n",
    "    geocodes: List[int],\n",
    "    year_week_start: int,\n",
    "    year_week_end: int,\n",
    "):\n",
    "    table_suffix = ''\n",
    "    if disease != 'dengue':\n",
    "        table_suffix = '_{}'.format(disease)\n",
    "    \n",
    "    schema_city = con.schema('Municipio')\n",
    "    t_hist = schema_city.table('Historico_alerta{}'.format(table_suffix))\n",
    "\n",
    "    case_level = (\n",
    "        ibis.case()\n",
    "        .when((t_hist.nivel.cast('string') == '1'), 'verde')\n",
    "        .when((t_hist.nivel.cast('string') == '2'), 'amarelo')\n",
    "        .when((t_hist.nivel.cast('string') == '3'), 'laranja')\n",
    "        .when((t_hist.nivel.cast('string') == '4'), 'vermelho')\n",
    "        .else_('-')\n",
    "        .end()\n",
    "    ).name(f'nivel_{disease}')\n",
    "\n",
    "    hist_keys = [\n",
    "        t_hist.SE.name(f'SE_{disease}'),\n",
    "        t_hist.casos.name(f'casos_{disease}'),\n",
    "        t_hist.p_rt1.name(f'p_rt1_{disease}'),\n",
    "        t_hist.casos_est.name(f'casos_est_{disease}'),\n",
    "        t_hist.p_inc100k.name(f'p_inc100k_{disease}'),\n",
    "        t_hist.nivel.name(f'level_code_{disease}'),\n",
    "        case_level,\n",
    "        t_hist.municipio_geocodigo.name(f'geocode_{disease}')\n",
    "    ]\n",
    "\n",
    "    hist_filter = (\n",
    "        (t_hist['SE'].between(year_week_start, year_week_end))\n",
    "        & (t_hist['municipio_geocodigo'].isin(geocodes))\n",
    "    )\n",
    "\n",
    "    return t_hist[hist_filter][hist_keys].sort_by(f'SE_{disease}')\n",
    "\n",
    "\n",
    "def get_twitter_expr(\n",
    "    geocodes_list: List[int], \n",
    "    year_week_start: int,\n",
    "    year_week_end: int\n",
    "):\n",
    "    epi_week_fn = get_epi_week_expr()\n",
    "    \n",
    "    t_tweet = schema_city.table('Tweet')\n",
    "    filter_tweet_cities = t_tweet.Municipio_geocodigo.isin(\n",
    "        geocodes_list\n",
    "    )\n",
    "    t_tweet = t_tweet[filter_tweet_cities]\n",
    "    t_tweet = t_tweet.mutate(SE_twitter=epi_week_fn(t_tweet.data_dia))\n",
    "\n",
    "    expr_tweet = t_tweet.groupby([\n",
    "        t_tweet.SE_twitter,\n",
    "        t_tweet.Municipio_geocodigo,\n",
    "\n",
    "    ]).aggregate(\n",
    "        n_tweets=t_tweet.numero.sum()\n",
    "    )\n",
    "\n",
    "    filter_tweet = (\n",
    "        t_tweet.SE_twitter.between(\n",
    "            general_param['year_week_start'], \n",
    "            general_param['year_week_end']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return expr_tweet[filter_tweet].sort_by(('SE_twitter', False))\n",
    "\n",
    "\n",
    "def get_climate_wu_expr(var_climate: str, station_id: str):\n",
    "    epi_week_fn = get_epi_week_expr()\n",
    "    \n",
    "    schema_city = con.schema('Municipio')\n",
    "    \n",
    "    t_climate_wu = schema_city.table('Clima_wu')\n",
    "    \n",
    "    expr_filter = t_climate_wu.Estacao_wu_estacao_id == station_id\n",
    "    t_climate_wu = t_climate_wu[expr_filter]\n",
    "    t_climate_wu = t_climate_wu.mutate(\n",
    "        epiweek_climate=epi_week_fn(t_climate_wu.data_dia)\n",
    "    )\n",
    "    \n",
    "    expr_climate_wu = t_climate_wu.groupby([\n",
    "        t_climate_wu.epiweek_climate\n",
    "    ]).aggregate(\n",
    "        **{var_climate: t_climate_wu[var_climate].mean().name(var_climate)}\n",
    "    )\n",
    "    \n",
    "    return expr_climate_wu.sort_by(t_climate_wu.epiweek_climate)\n",
    "    \n",
    "    \n",
    "hist_disease_expr = {}\n",
    "hist_prev = None\n",
    "joined_expr = None\n",
    "previous_disease = None\n",
    "\n",
    "for disease in DISEASES_SHORT:\n",
    "    hist_expr = get_hist_disease_expr(\n",
    "        disease, \n",
    "        general_param['geocodes_list'],\n",
    "        general_param['year_week_start'],\n",
    "        general_param['year_week_end'],\n",
    "    )\n",
    "    hist_disease_expr[disease] = hist_expr\n",
    "    \n",
    "    if joined_expr is None:\n",
    "        joined_expr = hist_expr\n",
    "    else:\n",
    "        # todo: review join approach\n",
    "        hist_prev = hist_disease_expr[previous_disease]\n",
    "        joined_cond = (\n",
    "            (hist_prev[f'SE_{previous_disease}'] == hist_expr[f'SE_{disease}'])\n",
    "            & (hist_prev[f'geocode_{previous_disease}'] == hist_expr[f'geocode_{disease}'])\n",
    "        )\n",
    "        joined_expr = joined_expr.left_join(\n",
    "            hist_expr,\n",
    "            joined_cond\n",
    "        )\n",
    "    previous_disease = disease\n",
    "\n",
    "# twitter data\n",
    "expr_tweet = get_twitter_expr(\n",
    "    general_param['geocodes_list'],\n",
    "    general_param['year_week_start'],\n",
    "    general_param['year_week_end'],\n",
    ")\n",
    "expr_dengue = hist_disease_expr['dengue']\n",
    "\n",
    "joined_expr = joined_expr.left_join(\n",
    "    expr_tweet, \n",
    "    (\n",
    "        (\n",
    "            expr_tweet.Municipio_geocodigo == expr_dengue.geocode_dengue\n",
    "        ) & (\n",
    "            expr_tweet.SE_twitter == expr_dengue.SE_dengue\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "climate_wu_expr = get_climate_wu_expr(\n",
    "    general_param['var_climate'], \n",
    "    general_param['station_id']\n",
    ")\n",
    "\n",
    "joined_expr = joined_expr.left_join(\n",
    "    climate_wu_expr, \n",
    "    hist_disease_expr['dengue'].SE_dengue == climate_wu_expr.epiweek_climate\n",
    ").materialize()\n",
    "\n",
    "epiweek2date_fn = get_epiweek2date_expr()\n",
    "\n",
    "k = ['casos', 'p_inc100k', 'casos_est', 'p_rt1', 'nivel', 'level_code']\n",
    "proj = [joined_expr['{}_{}'.format(v, d)] for v in k for d in DISEASES_SHORT]\n",
    "proj.extend([\n",
    "    joined_expr[var_climate],\n",
    "    joined_expr['n_tweets'],\n",
    "    joined_expr['geocode_dengue'].name('geocode'),\n",
    "    joined_expr['SE_dengue'].name('SE'),\n",
    "    epiweek2date_fn(joined_expr.SE_dengue).name('init_date_week'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_read_disease_data(\n",
    "    cities: dict, station_id: str, year_week: int, var_climate: str\n",
    ") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        :param cities:\n",
    "        :param station_id:\n",
    "        :param year_week:\n",
    "        :param var_climate:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        DISEASES = ['dengue', 'chik', 'zika']\n",
    "\n",
    "        k = ['casos', 'p_inc100k', 'casos_est', 'p_rt1', 'nivel', 'level_code']\n",
    "\n",
    "        k = ['{}_{}'.format(v, d) for v in k for d in DISEASES]\n",
    "\n",
    "        k.append(var_climate)\n",
    "        k.append('n_tweets')\n",
    "        k.append('geocode_dengue AS geocode')\n",
    "        k.append('\"SE_dengue\" AS \"SE\"')\n",
    "        k.append('epiweek2date(\"SE_dengue\") AS init_date_week')\n",
    "\n",
    "        general_param = {\n",
    "            'year_week_start': year_week - 200,\n",
    "            'year_week_end': year_week,\n",
    "            'geocodes': ','.join(map(lambda v: \"'{}'\".format(v), cities)),\n",
    "            'var_climate': var_climate,\n",
    "            'station_id': station_id,\n",
    "        }\n",
    "\n",
    "        sql = ''\n",
    "        previous_disease = ''\n",
    "        for disease in DISEASES:\n",
    "            _param = dict(general_param)\n",
    "            _param['disease'] = disease\n",
    "\n",
    "            table_suffix = ''\n",
    "            if disease != 'dengue':\n",
    "                table_suffix = '_{}'.format(disease)\n",
    "\n",
    "            _param['table_suffix'] = table_suffix\n",
    "\n",
    "            sql_ = (\n",
    "                '''\n",
    "            (SELECT\n",
    "               hist.\"SE\" AS \"SE_%(disease)s\",\n",
    "               hist.casos AS casos_%(disease)s,\n",
    "               hist.p_rt1 AS p_rt1_%(disease)s,\n",
    "               hist.casos_est AS casos_est_%(disease)s,\n",
    "               hist.p_inc100k AS p_inc100k_%(disease)s,\n",
    "               hist.nivel AS level_code_%(disease)s,\n",
    "               (CASE\n",
    "                  WHEN hist.nivel=1 THEN 'verde'\n",
    "                  WHEN hist.nivel=2 THEN 'amarelo'\n",
    "                  WHEN hist.nivel=3 THEN 'laranja'\n",
    "                  WHEN hist.nivel=4 THEN 'vermelho'\n",
    "                  ELSE '-'\n",
    "                END) AS nivel_%(disease)s,\n",
    "                hist.municipio_geocodigo AS geocode_%(disease)s\n",
    "            FROM\n",
    "             \"Municipio\".\"Historico_alerta%(table_suffix)s\" AS hist\n",
    "            WHERE\n",
    "             hist.\"SE\" BETWEEN %(year_week_start)s AND %(year_week_end)s\n",
    "             AND hist.municipio_geocodigo IN (%(geocodes)s)\n",
    "            ORDER BY \"SE_%(disease)s\" DESC\n",
    "            ) AS %(disease)s\n",
    "            '''\n",
    "                % _param\n",
    "            )\n",
    "\n",
    "            if not sql:\n",
    "                sql = sql_\n",
    "            else:\n",
    "                sql += '''\n",
    "                    LEFT JOIN {0}\n",
    "                    ON (\n",
    "                      {1}.\"SE_{1}\" = {2}.\"SE_{2}\"\n",
    "                      AND {1}.geocode_{1} = {2}.geocode_{2}\n",
    "                    )\n",
    "                '''.format(\n",
    "                    sql_, previous_disease, disease\n",
    "                )\n",
    "            previous_disease = disease\n",
    "\n",
    "        tweet_join = (\n",
    "            '''\n",
    "        LEFT JOIN (\n",
    "           SELECT\n",
    "             epi_week(data_dia) AS \"SE_twitter\",\n",
    "             SUM(numero) as n_tweets,\n",
    "             \"Municipio_geocodigo\"\n",
    "           FROM \"Municipio\".\"Tweet\"\n",
    "           WHERE\n",
    "             \"Municipio_geocodigo\" IN (%(geocodes)s)\n",
    "             AND epi_week(data_dia)\n",
    "               BETWEEN %(year_week_start)s AND %(year_week_end)s\n",
    "           GROUP BY \"SE_twitter\", \"Municipio_geocodigo\"\n",
    "           ORDER BY \"SE_twitter\" DESC\n",
    "        ) AS tweets\n",
    "           ON (\n",
    "             \"Municipio_geocodigo\"=dengue.\"geocode_dengue\"\n",
    "             AND tweets.\"SE_twitter\"=dengue.\"SE_dengue\"\n",
    "           )\n",
    "        '''\n",
    "            % general_param\n",
    "        )\n",
    "\n",
    "        climate_join = (\n",
    "            '''\n",
    "        LEFT JOIN (\n",
    "          SELECT\n",
    "             epi_week(data_dia) AS epiweek_climate,\n",
    "             AVG(%(var_climate)s) AS %(var_climate)s\n",
    "          FROM \"Municipio\".\"Clima_wu\"\n",
    "          WHERE \"Estacao_wu_estacao_id\" = '%(station_id)s'\n",
    "          GROUP BY epiweek_climate\n",
    "          ORDER BY epiweek_climate\n",
    "        ) AS climate_wu\n",
    "           ON (dengue.\"SE_dengue\"=climate_wu.epiweek_climate)\n",
    "        '''\n",
    "            % general_param\n",
    "        )\n",
    "\n",
    "        sql += climate_join + tweet_join\n",
    "\n",
    "        sql = ' SELECT {} FROM ({}) AS data'.format(','.join(k), sql)\n",
    "        df = pd.read_sql(sql, index_col='SE', con=con.con)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 370 ms, sys: 13.1 ms, total: 383 ms\n",
      "Wall time: 5.2 s\n",
      "CPU times: user 107 ms, sys: 14.5 ms, total: 121 ms\n",
      "Wall time: 6 s\n"
     ]
    }
   ],
   "source": [
    "%time joined_expr[proj].execute()\n",
    "#\n",
    "%time df_sql = sql_read_disease_data(cities, station_id, year_week, var_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sql.init_date_week.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_sql = df_sql.copy()\n",
    "_df_sql = _df_sql.astype({'init_date_week': 'datetime64[ns]'})\n",
    "_df_sql.init_date_week.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibis = joined_expr[proj].execute()\n",
    "# set index\n",
    "_df_ibis = df_ibis.set_index('SE', drop=True)\n",
    "# use the same data type for both dataframes\n",
    "_df_ibis = _df_ibis.astype({\n",
    "    col_name: col_type for col_name, col_type in df_sql.dtypes.items()\n",
    "})\n",
    "# reformat datatype\n",
    "_df_ibis.init_date_week = _df_ibis.init_date_week.apply(lambda v: v.to_pydatetime())\n",
    "_df_sql.init_date_week = _df_sql.init_date_week.apply(lambda v: v.to_pydatetime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 379 ms, sys: 7.06 ms, total: 386 ms\n",
      "Wall time: 5.27 s\n",
      "IBIS >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19320 entries, 201802 to 202002\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   casos_dengue       19320 non-null  int64         \n",
      " 1   casos_chik         19320 non-null  int64         \n",
      " 2   casos_zika         19320 non-null  int64         \n",
      " 3   p_inc100k_dengue   19320 non-null  float64       \n",
      " 4   p_inc100k_chik     19320 non-null  float64       \n",
      " 5   p_inc100k_zika     19320 non-null  float64       \n",
      " 6   casos_est_dengue   19320 non-null  float64       \n",
      " 7   casos_est_chik     19320 non-null  float64       \n",
      " 8   casos_est_zika     19320 non-null  float64       \n",
      " 9   p_rt1_dengue       19320 non-null  float64       \n",
      " 10  p_rt1_chik         19320 non-null  float64       \n",
      " 11  p_rt1_zika         19320 non-null  float64       \n",
      " 12  nivel_dengue       19320 non-null  object        \n",
      " 13  nivel_chik         19320 non-null  object        \n",
      " 14  nivel_zika         19320 non-null  object        \n",
      " 15  level_code_dengue  19320 non-null  int64         \n",
      " 16  level_code_chik    19320 non-null  int64         \n",
      " 17  level_code_zika    19320 non-null  int64         \n",
      " 18  umid_max           19320 non-null  float64       \n",
      " 19  n_tweets           11060 non-null  float64       \n",
      " 20  geocode            19320 non-null  int64         \n",
      " 21  init_date_week     19320 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(11), int64(7), object(3)\n",
      "memory usage: 6.4 MB\n",
      "CPU times: user 110 ms, sys: 15.9 ms, total: 126 ms\n",
      "Wall time: 5.98 s\n",
      "SQL >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19320 entries, 201802 to 202002\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   casos_dengue       19320 non-null  int64         \n",
      " 1   casos_chik         19320 non-null  int64         \n",
      " 2   casos_zika         19320 non-null  int64         \n",
      " 3   p_inc100k_dengue   19320 non-null  float64       \n",
      " 4   p_inc100k_chik     19320 non-null  float64       \n",
      " 5   p_inc100k_zika     19320 non-null  float64       \n",
      " 6   casos_est_dengue   19320 non-null  float64       \n",
      " 7   casos_est_chik     19320 non-null  float64       \n",
      " 8   casos_est_zika     19320 non-null  float64       \n",
      " 9   p_rt1_dengue       19320 non-null  float64       \n",
      " 10  p_rt1_chik         19320 non-null  float64       \n",
      " 11  p_rt1_zika         19320 non-null  float64       \n",
      " 12  nivel_dengue       19320 non-null  object        \n",
      " 13  nivel_chik         19320 non-null  object        \n",
      " 14  nivel_zika         19320 non-null  object        \n",
      " 15  level_code_dengue  19320 non-null  int64         \n",
      " 16  level_code_chik    19320 non-null  int64         \n",
      " 17  level_code_zika    19320 non-null  int64         \n",
      " 18  umid_max           19320 non-null  float64       \n",
      " 19  n_tweets           11060 non-null  float64       \n",
      " 20  geocode            19320 non-null  int64         \n",
      " 21  init_date_week     19320 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(11), int64(7), object(3)\n",
      "memory usage: 6.4 MB\n"
     ]
    }
   ],
   "source": [
    "# TESTS\n",
    "\n",
    "a_time = %time df_ibis = joined_expr[proj].execute()\n",
    "print(\"IBIS\",\">\"*40,\"{}\".format(a_time))\n",
    "_df_ibis.info(memory_usage='deep')\n",
    "\n",
    "b_time = %time df_sql = sql_read_disease_data(cities, station_id, year_week, var_climate)\n",
    "print(\"SQL\",\">\"*40,\"{}\".format(b_time))\n",
    "_df_sql.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "\n",
    "def extractweekday(x=datetime.datetime):\n",
    "    # Extract weekday as [Sun-Sat] |-> [0-6]\n",
    "    # isoweekday() returns weekday with [Mon-Sun] as [1-7]\n",
    "    w = x.isoweekday() % 7\n",
    "    return w\n",
    "\n",
    "\n",
    "def firstepiday(year=int):\n",
    "    day = datetime.datetime.strptime('%s-01-01' % year, '%Y-%m-%d')\n",
    "\n",
    "    day_week = extractweekday(day)\n",
    "\n",
    "    # Whe want day1 to correspond to the first day of the first epiweek.\n",
    "    # That is, we need the Sunday corresponding to epiweek=%Y01\n",
    "    # If first day of the year is between Sunday and Wednesday,\n",
    "    # epiweek 01 includes it. Otherwise, it is still the last epiweek\n",
    "    # of the previous year\n",
    "    if day_week < 4:\n",
    "        day = day - datetime.timedelta(days=day_week)\n",
    "    else:\n",
    "        day = day + datetime.timedelta(days=(7 - day_week))\n",
    "\n",
    "    return day\n",
    "\n",
    "\n",
    "def lastepiday(year=int):\n",
    "    day = datetime.datetime.strptime('%s-12-31' % year, '%Y-%m-%d')\n",
    "\n",
    "    day_week = extractweekday(day)\n",
    "\n",
    "    # Whe want day to correspond to the last day of the last epiweek.\n",
    "    # That is, we need the corresponding Saturday\n",
    "    # If the last day of the year is between Sunday and Tuesday,\n",
    "    # epiweek 01 of the next year includes it.\n",
    "    # Otherwise, it is still the last epiweek of the current year\n",
    "    if day_week < 3:\n",
    "        day = day - datetime.timedelta(days=(day_week + 1))\n",
    "    else:\n",
    "        day = day + datetime.timedelta(days=(6 - day_week))\n",
    "\n",
    "    return day\n",
    "\n",
    "def episem(x, sep='W', out='YW'):\n",
    "\n",
    "    \"\"\"\n",
    "    Return Brazilian corresponding epidemiological week from x.\n",
    "\n",
    "    :param x: Input date. Can be a string in the format %Y-%m-%d or\n",
    "      datetime.datetime\n",
    "    :param sep: Year and week separator.\n",
    "    :param out: Output format. 'YW' returns sep.join(epiyear,epiweek).\n",
    "     'Y' returns epiyear only. 'W' returns epiweek only.\n",
    "    :return: str\n",
    "    \"\"\"\n",
    "\n",
    "    def out_format(year, week, out, sep='W'):\n",
    "        if out == 'YW':\n",
    "            return '%s%s%02d' % (year, sep, week)\n",
    "        if out == 'Y':\n",
    "            return '%s' % (year)\n",
    "        if out == 'W':\n",
    "            return '%02d' % week\n",
    "\n",
    "    if type(x) != datetime.datetime:\n",
    "        if str(x) == '' or x is None or (type(x) != str and np.isnan(x)):\n",
    "            return None\n",
    "        x = datetime.datetime.strptime(x, '%Y-%m-%d')\n",
    "\n",
    "    epiyear = x.year\n",
    "    epiend = lastepiday(epiyear)\n",
    "\n",
    "    if x > epiend:\n",
    "        epiyear += 1\n",
    "        return out_format(epiyear, 1, out, sep)\n",
    "\n",
    "    epistart = firstepiday(epiyear)\n",
    "\n",
    "    # If current date is before its year first epiweek,\n",
    "    # then our base year is the previous one\n",
    "    if x < epistart:\n",
    "        epiyear -= 1\n",
    "        epistart = firstepiday(epiyear)\n",
    "\n",
    "    epiweek = int(((x - epistart) / 7).days) + 1\n",
    "\n",
    "    return out_format(epiyear, epiweek, out, sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_original(df):\n",
    "    if not df.empty:\n",
    "        dfs = []\n",
    "\n",
    "        # merge with a range date dataframe to keep empty week on the data\n",
    "        ts_date = pd.date_range(\n",
    "            df['init_date_week'].min(),\n",
    "            df['init_date_week'].max(),\n",
    "            freq='7D',\n",
    "        )\n",
    "        df_date = pd.DataFrame({'init_date_week': ts_date})\n",
    "\n",
    "        for geocode in df.geocode.unique():\n",
    "            df_ = df[df.geocode == geocode].sort_values('init_date_week')\n",
    "\n",
    "            df_date_ = df_date.set_index(\n",
    "                df_.init_date_week.map(\n",
    "                    lambda x: int(episem(str(x)[:10], sep=''))\n",
    "                ),\n",
    "                drop=True,\n",
    "            )\n",
    "\n",
    "            df_.index.name = None\n",
    "            df_date_.index.name = None\n",
    "\n",
    "            df_['init_date_week'] = pd.to_datetime(\n",
    "                df_['init_date_week'], errors='coerce'\n",
    "            )\n",
    "\n",
    "            dfs.append(\n",
    "                pd.merge(\n",
    "                    df_,\n",
    "                    df_date_,\n",
    "                    how='outer',\n",
    "                    on='init_date_week',\n",
    "                    left_index=True,\n",
    "                    right_index=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        df = pd.concat(dfs)\n",
    "\n",
    "    df.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "    for d in DISEASES_SHORT:\n",
    "        k = 'p_rt1_{}'.format(d)\n",
    "        df[k] = (df[k] * 100).fillna(0)\n",
    "        k = 'casos_est_{}'.format(d)\n",
    "        df[k] = df[k].fillna(0).round(0)\n",
    "        k = 'p_inc100k_{}'.format(d)\n",
    "        df[k] = df[k].fillna(0).round(0)\n",
    "\n",
    "        df.rename(\n",
    "            columns={\n",
    "                'p_inc100k_{}'.format(d): 'incidência {}'.format(d),\n",
    "                'casos_{}'.format(d): 'casos notif. {}'.format(d),\n",
    "                'casos_est_{}'.format(d): 'casos est. {}'.format(d),\n",
    "                'p_rt1_{}'.format(d): 'pr(incid. subir) {}'.format(d),\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "    df.n_tweets = df.n_tweets.fillna(0).round(0)\n",
    "\n",
    "    return df.rename(\n",
    "        columns={\n",
    "            'umid_max': 'umid.max',\n",
    "            'temp_min': 'temp.min',\n",
    "            'n_tweets': 'tweets',\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_new(df):\n",
    "    if not df.empty:\n",
    "        dfs = []\n",
    "\n",
    "        # merge with a range date dataframe to keep empty week on the data\n",
    "        ts_date = pd.date_range(\n",
    "            df['init_date_week'].min(),\n",
    "            df['init_date_week'].max(),\n",
    "            freq='7D',\n",
    "        )\n",
    "        df_date = pd.DataFrame({'init_date_week': ts_date})\n",
    "\n",
    "        for geocode in df.geocode.unique():\n",
    "            df_ = df[df.geocode == geocode].sort_values('init_date_week')\n",
    "\n",
    "            df_date_ = df_date.set_index(\n",
    "                df_.init_date_week.map(\n",
    "                    lambda x: int(episem(str(x)[:10], sep=''))\n",
    "                ),\n",
    "                drop=True,\n",
    "            )\n",
    "\n",
    "            df_.index.name = None\n",
    "            df_date_.index.name = None\n",
    "\n",
    "            df_['init_date_week'] = pd.to_datetime(\n",
    "                df_['init_date_week'], errors='coerce'\n",
    "            )\n",
    "\n",
    "            dfs.append(\n",
    "                pd.merge(\n",
    "                    df_,\n",
    "                    df_date_,\n",
    "                    how='outer',\n",
    "                    on='init_date_week',\n",
    "                    left_index=True,\n",
    "                    right_index=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        df = pd.concat(dfs)\n",
    "\n",
    "    df.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "    for d in DISEASES_SHORT:\n",
    "        k = 'p_rt1_{}'.format(d)\n",
    "        df[k] = (df[k] * 100).fillna(0)\n",
    "        k = 'casos_est_{}'.format(d)\n",
    "        df[k] = df[k].fillna(0).round(0)\n",
    "        k = 'p_inc100k_{}'.format(d)\n",
    "        df[k] = df[k].fillna(0).round(0)\n",
    "\n",
    "        df.rename(\n",
    "            columns={\n",
    "                'p_inc100k_{}'.format(d): 'incidência {}'.format(d),\n",
    "                'casos_{}'.format(d): 'casos notif. {}'.format(d),\n",
    "                'casos_est_{}'.format(d): 'casos est. {}'.format(d),\n",
    "                'p_rt1_{}'.format(d): 'pr(incid. subir) {}'.format(d),\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "    df.n_tweets = df.n_tweets.fillna(0).round(0)\n",
    "\n",
    "    return df.rename(\n",
    "        columns={\n",
    "            'umid_max': 'umid.max',\n",
    "            'temp_min': 'temp.min',\n",
    "            'n_tweets': 'tweets',\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 3.04 ms, total: 1.22 s\n",
      "Wall time: 1.22 s\n",
      "############################################################\n",
      "CPU times: user 1.19 s, sys: 0 ns, total: 1.19 s\n",
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casos notif. dengue</th>\n",
       "      <th>casos notif. chik</th>\n",
       "      <th>casos notif. zika</th>\n",
       "      <th>incidência dengue</th>\n",
       "      <th>incidência chik</th>\n",
       "      <th>incidência zika</th>\n",
       "      <th>casos est. dengue</th>\n",
       "      <th>casos est. chik</th>\n",
       "      <th>casos est. zika</th>\n",
       "      <th>pr(incid. subir) dengue</th>\n",
       "      <th>...</th>\n",
       "      <th>nivel_dengue</th>\n",
       "      <th>nivel_chik</th>\n",
       "      <th>nivel_zika</th>\n",
       "      <th>level_code_dengue</th>\n",
       "      <th>level_code_chik</th>\n",
       "      <th>level_code_zika</th>\n",
       "      <th>umid.max</th>\n",
       "      <th>tweets</th>\n",
       "      <th>geocode</th>\n",
       "      <th>init_date_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201802</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83.655999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2314102</td>\n",
       "      <td>2018-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201802</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83.655999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2304806</td>\n",
       "      <td>2018-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201802</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83.655999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2304707</td>\n",
       "      <td>2018-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201802</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83.655999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2304657</td>\n",
       "      <td>2018-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201802</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83.655999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2304608</td>\n",
       "      <td>2018-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86.652778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2304954</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86.652778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2305001</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86.652778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2305100</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202002</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.3268</td>\n",
       "      <td>...</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86.652778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2305233</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>verde</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86.652778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2300101</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        casos notif. dengue  casos notif. chik  casos notif. zika  \\\n",
       "201802                    0                  0                  0   \n",
       "201802                    0                  0                  0   \n",
       "201802                    0                  0                  0   \n",
       "201802                    0                  0                  0   \n",
       "201802                    0                  0                  0   \n",
       "...                     ...                ...                ...   \n",
       "202002                    0                  0                  0   \n",
       "202002                    0                  0                  0   \n",
       "202002                    0                  0                  0   \n",
       "202002                    1                  0                  0   \n",
       "202002                    0                  0                  0   \n",
       "\n",
       "        incidência dengue  incidência chik  incidência zika  \\\n",
       "201802                0.0              0.0              0.0   \n",
       "201802                0.0              0.0              0.0   \n",
       "201802                0.0              0.0              0.0   \n",
       "201802                0.0              0.0              0.0   \n",
       "201802                0.0              0.0              0.0   \n",
       "...                   ...              ...              ...   \n",
       "202002                0.0              0.0              0.0   \n",
       "202002                0.0              0.0              0.0   \n",
       "202002                0.0              0.0              0.0   \n",
       "202002                2.0              0.0              0.0   \n",
       "202002                0.0              0.0              0.0   \n",
       "\n",
       "        casos est. dengue  casos est. chik  casos est. zika  \\\n",
       "201802                0.0              0.0              0.0   \n",
       "201802                0.0              0.0              0.0   \n",
       "201802                0.0              0.0              0.0   \n",
       "201802                0.0              0.0              0.0   \n",
       "201802                0.0              0.0              0.0   \n",
       "...                   ...              ...              ...   \n",
       "202002                0.0              0.0              0.0   \n",
       "202002                0.0              0.0              0.0   \n",
       "202002                0.0              0.0              0.0   \n",
       "202002                1.0              0.0              0.0   \n",
       "202002                0.0              0.0              0.0   \n",
       "\n",
       "        pr(incid. subir) dengue  ...  nivel_dengue  nivel_chik nivel_zika  \\\n",
       "201802                   0.0000  ...         verde       verde      verde   \n",
       "201802                  50.0000  ...         verde       verde      verde   \n",
       "201802                   0.0000  ...         verde       verde      verde   \n",
       "201802                   0.0000  ...         verde       verde      verde   \n",
       "201802                  50.0000  ...         verde       verde      verde   \n",
       "...                         ...  ...           ...         ...        ...   \n",
       "202002                   0.0000  ...         verde       verde      verde   \n",
       "202002                   0.0000  ...         verde       verde      verde   \n",
       "202002                   0.0000  ...         verde       verde      verde   \n",
       "202002                  96.3268  ...         verde       verde      verde   \n",
       "202002                   0.0000  ...         verde       verde      verde   \n",
       "\n",
       "       level_code_dengue level_code_chik  level_code_zika   umid.max  tweets  \\\n",
       "201802                 1               1                1  83.655999     0.0   \n",
       "201802                 1               1                1  83.655999     0.0   \n",
       "201802                 1               1                1  83.655999     0.0   \n",
       "201802                 1               1                1  83.655999     0.0   \n",
       "201802                 1               1                1  83.655999     0.0   \n",
       "...                  ...             ...              ...        ...     ...   \n",
       "202002                 1               1                1  86.652778     0.0   \n",
       "202002                 1               1                1  86.652778     0.0   \n",
       "202002                 1               1                1  86.652778     0.0   \n",
       "202002                 1               1                1  86.652778     0.0   \n",
       "202002                 1               1                1  86.652778     0.0   \n",
       "\n",
       "        geocode  init_date_week  \n",
       "201802  2314102      2018-01-07  \n",
       "201802  2304806      2018-01-07  \n",
       "201802  2304707      2018-01-07  \n",
       "201802  2304657      2018-01-07  \n",
       "201802  2304608      2018-01-07  \n",
       "...         ...             ...  \n",
       "202002  2304954      2020-01-05  \n",
       "202002  2305001      2020-01-05  \n",
       "202002  2305100      2020-01-05  \n",
       "202002  2305233      2020-01-05  \n",
       "202002  2300101      2020-01-05  \n",
       "\n",
       "[19320 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time format_df_original(_df_sql)\n",
    "print(\"#\"*60)\n",
    "%time format_df_new(_df_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
